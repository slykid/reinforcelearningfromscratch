
# 챕터7: 신경망과 Q러닝

## DeZero 기초
- 파이토치와 같은 최신 딥러닝 프레임워크랑 똑같은 개념으로 설계된 프레임워크
- 데이터를 넘파이의 ndarray처럼 다룰 수 있고, 역전파를 통해 미분을 구할 수 있음
- 미분을 이용해 매개변수를 갱신하는 경사하강법을 구현할 수 있음

### DeZero 사용법
- variable: 넘파이의 다차원 배열을 감싸는 클래스

```python
import numpy as np
from dezero import Variable # dezero 모듈에서 Variable 임포트

x_np = np.array(5.0) # 넘파이 배열 생성
x = Variable(x_np) # Variable 인스턴스 생성

y = 3 * x ** 2 # 넘파이 다차원 배열처럼 사용
print(y)
```


- backward(): 메서드 호출 시 역전파가 수행되어 각 변수의 미분을 구할 수 있음

### 다차원 배열(텐서)과 함수

<br>
<img width="223" height="66" alt="image" src="https://github.com/user-attachments/assets/61ef9e50-200d-4c8e-9dda-1cc2b6e8c2cb" />
<br>

* 스칼라: 하나의 숫자
* 벡터: 하나의 축을 따라 숫자가 나열됨
* 행렬: 축이 두 개로 늘어남
* 텐서: 다차원 배열
* 차원(축): 원소의 배열에는 방향이 있음
* 벡터의 내적: 대응하는 원소의 곱을 모두 더한 것

<br>
<img width="213" height="39" alt="image" src="https://github.com/user-attachments/assets/27eb4c47-06e5-4b88-9b04-fd523900a85d" />
<br>
* 행렬의 곱: 왼쪽 행렬의 가로 벡터와 오른쪽 행렬의 세로 벡터 사이의 내적을 계산함
<br>
<img width="192" height="134" alt="image" src="https://github.com/user-attachments/assets/66efc340-593c-473e-bd73-cb02835301a1" />
<br>
* 형상: 행렬 곱에서는 해당 차원(축)의 원소 개수를 일치시켜야 함
<br> 
  <img width="230" height="77" alt="image" src="https://github.com/user-attachments/assets/fdca1743-b4b6-4c87-b240-a478198f7405" />


### 최적화
* 로젠브록 함수: 진정한 최솟값을 찾기 어렵고, 함수의 형태가 특징적이기 때문에 최적화 벤치마크의 용도로 널리 쓰임
* 최적화: 함수가 최솟값(또는 최댓값)이 되게 하는 인수(입력)을 찾는 작업


#### 로젠브록 함수 예시
<br>
<img width="191" height="41" alt="image" src="https://github.com/user-attachments/assets/ffb6f1fa-c00a-4c52-8c55-6b2cb6076c4b" />

<br>
<img width="486" height="54" alt="image" src="https://github.com/user-attachments/assets/5965ca6d-514f-4241-806f-464be5ed855e" />
<br>
<img width="328" height="38" alt="image" src="https://github.com/user-attachments/assets/0ba309dd-0080-4ae8-8cb2-9f2ed72294e0" />

* 기울기 or 기울기 벡터: 두 미분값(-2.0, 400.0)을 모아 만든 벡터. 각 지점에서 함수의 출력을 가장 크게 증가시키는 방향
* 반대로, 기울기에 마이너스를 곱한 (2.0. -400.0) 방향은 y의 값을 가장 크게 감소시키는 방향
* 경사 하강법: 기울기 방향으로 일정 거리만큼 이동하고, 그 지점에서 다시 기울기를 구하는 일을 반복하면 원하는 지점(최댓값 or 최솟값)에 가까워지는 방법


## 선형회귀

### 토이 데이터셋


* 경사하강법 적용
```python
# 초기 변수 설정
X0 = Variable(np.array(0.0))
X1 = Variable(np.array(2.0))

# 하이퍼파라미터 설정
iters = 10000   # 반복 횟수
lr = 0.001      # 학습률

# 경사 하강 반복
for i in range(iters):
    print(X0, X1)
    Y = rosenbrock(X0, X1)

    # 이전 반복에서 더해진 미분 초기화
    X0.cleargrad()
    X1.cleargrad()

    # 미분(역전파)
    Y.backward()

    # 변수 갱신
    X0.data -= lr * X0.grad.data
    X1.data -= lr * X1.grad.data

print(X0, X1)

```

* 선형회귀: 예측 모델이 선형(직선)인 회귀. 손실함수로 평균 제곱오차를 사용함
* 회귀: x값에 서 실수값인 y를 예측하는 일
* 선형회귀 함수: y = Wx+ b (w: 스칼라), 직선임
* 잔차: 데이터와 예측값의 차이
* 목표: 잔차를 줄여야 함. 손실함수가 최소가 되는 W와 b를 찾는 것

```python
import numpy as np

# 시드 고정 (재현 가능성 확보)
np.random.seed(0)

# 입력 데이터 x (0~1 사이 난수 100개, 열벡터 형태)
x = np.random.rand(100, 1)

# 출력 데이터 y = 5 + 2x + 잡음
y = 5 + 2 * x + np.random.rand(100, 1)

```



* 평균 제곱 오차: 모델의 예측값과 실제 데이터가 얼마나 잘 맞는지 제곱 오차를 모두 더한 다음 N 으로 나눠 평균을 구하는 방법

<br>
<img width="168" height="55" alt="image" src="https://github.com/user-attachments/assets/7bb67364-8cf2-47f6-b167-0f49ee495c7e" />
<br>
<img width="373" height="282" alt="image" src="https://github.com/user-attachments/assets/35b6a293-4280-4785-99d3-cd9cd2b14be9" />
<br>

### 선형 회귀 구현

#### 노이즈가 포함된 데이터셋

- 전반부 코드

```python
import numpy as np
from dezero import Variable
import dezero.functions as F

# -----------------------------
# 1. 토이 데이터셋 생성
# -----------------------------
np.random.seed(0)
X = np.random.rand(100, 1)
y = 5 + 2 * X + np.random.rand(100, 1)

# Variable로 감싸서 연산 추적 가능
X, y = Variable(X), Variable(y)

# -----------------------------
# 2. 매개변수 정의
# -----------------------------
W = Variable(np.zeros((1, 1)))  # 가중치
b = Variable(np.zeros(1))       # 편향

# -----------------------------
# 3. 예측 함수 정의
# -----------------------------
def predict(X):
    y_pred = F.matmul(X, W) + b  # 행렬 곱으로 여러 데이터 일괄 계산
    return y_pred

```


- 행렬 곱 연산 시 형상 변화: 대응하는 차원의 원소 수가 일치함



<br>
<img width="225" height="79" alt="image" src="https://github.com/user-attachments/assets/fdc9ee3a-1f59-40f3-897e-1303f3d12e23" />
<br>

- 후반부 코드

```python
# -----------------------------
# 평균 제곱 오차 (MSE) 계산 함수
# -----------------------------
def mean_squared_error(x0, x1):
    diff = x0 - x1
    return F.sum(diff ** 2) / len(diff)

# -----------------------------
# 경사 하강법으로 매개변수 갱신
# -----------------------------
lr = 0.1      # 학습률
iters = 100   # 반복 횟수

for i in range(iters):
    # 예측
    y_pred = predict(X)

    # 손실 계산
    loss = mean_squared_error(y, y_pred)
    # 또는 loss = F.mean_squared_error(y, y_pred)

    # 기울기 초기화
    W.cleargrad()
    b.cleargrad()

    # 역전파 (기울기 계산)
    loss.backward()

    # 매개변수 갱신
    W.data -= lr * W.grad.data
    b.data -= lr * b.grad.data

    # 10회 단위로 손실 출력
    if i % 10 == 0:
        print(loss.data)

print('==== 결과 ====')
print('W =', W.data)
print('b =', b.data)

```

- mean_squared_error(x0, x1): 평균 제곱 오차를 구하는 함수
- 코드를 실행하면 손실 함수의 출력값이 줄어듦
<br>

#### 학습 후 모델 결과
<br>
<img width="434" height="332" alt="image" src="https://github.com/user-attachments/assets/f95bfe42-034b-4352-b253-4b97acb089a4" />



## 신경망

### 비선형 데이터셋

- 비선형 데이터셋은 선형회귀로 대응할 수 없음
- 이를 위한 해결방안은 '신경망'

### 선형 변환과 활성화 함수

- 선형변환(= 어파인변환): 입력 매개변수 x와 w 사이의 행렬 곱을 구한 다음 b를 더함. 완전 연결 계층에 대응함
- w: 가중치
- b:  편향
- y = F.matual(x, w) + b
- y = F.linear(x, w, b)
- 활성화 함수: 비선형 변환을 수행하는 함수, 결과가 직선이 아닌 함수 (예: 시그모이드, ReLU)

#### 시그모이드 함수, ReLU 함수
<img width="488" height="175" alt="image" src="https://github.com/user-attachments/assets/5dcdfabd-736f-4843-afac-046fa0635fe6" />

### 신경망 구현

- 신경망 추론: 신경망은 선형 변환과 활성화 함수를 순서대로 적용함
- 추론을 제대로 하려면 학습이 선행되어어야 함
- 신경망 학습에서 추론 처리 후에 손실함수 추가 -> 그 손실 함수의 출력을 최소화하는 매개변수를 찾음
- 신경망은 가중치 초깃값을 무작위로 설정하는 것이 좋음
  
#### 2층 신경망 구현
- 신경망은 선형 변환과 활성화 함수를 번갈아 사용함
  <br>
<img width="362" height="149" alt="image" src="https://github.com/user-attachments/assets/e674d2b7-4ec6-465d-8a6c-a0767d03c2cb" />

#### 신경망 학습

```python
import numpy as np
from dezero import Variable
import dezero.functions as F

# -----------------------------
# 1. 데이터셋
# -----------------------------
np.random.seed(0)
x = np.random.rand(100, 1)
y = np.sin(2 * np.pi * x) + np.random.rand(100, 1)

# -----------------------------
# 2. 매개변수 초기값
#    I=입력 차원 수, H=은닉층 차원 수, O=출력 차원 수
# -----------------------------
I, H, O = 1, 10, 1

W1 = Variable(0.01 * np.random.rand(I, H))   # 첫 번째 층의 가중치
b1 = Variable(np.zeros(H))                   # 첫 번째 층의 편향
W2 = Variable(0.01 * np.random.rand(H, O))   # 두 번째 층의 가중치
b2 = Variable(np.zeros(O))                   # 두 번째 층의 편향

# -----------------------------
# 3. 신경망 추론
# -----------------------------
def predict(x):
    y = F.linear(x, W1, b1)
    y = F.sigmoid(y)
    y = F.linear(y, W2, b2)
    return y

# -----------------------------
# 4. 신경망 학습(매개변수 갱신)
# -----------------------------
lr = 0.2
iters = 10000

for i in range(iters):
    # 예측
    y_pred = predict(x)

    # 손실(MSE)
    loss = F.mean_squared_error(y, y_pred)

    # 기울기 초기화
    W1.cleargrad()
    b1.cleargrad()
    W2.cleargrad()
    b2.cleargrad()

    # 역전파
    loss.backward()

    # 매개변수 갱신
    W1.data -= lr * W1.grad.data
    b1.data -= lr * b1.grad.data
    W2.data -= lr * W2.grad.data
    b2.data -= lr * b2.grad.data

    # 1000회마다 손실 출력
    if i % 1000 == 0:
        print(loss.data)

```

#### 학습이 끝난 신경망으로 예측한 곡선
<br>
<img width="436" height="336" alt="image" src="https://github.com/user-attachments/assets/3f4f55ad-ffa9-4826-9199-6fba104e80ed" />


### 계층과 모델

- Linear 계층을 사용하는 코드

```python
# 초기 변수 설정
X0 = Variable(np.array(0.0))
X1 = Variable(np.array(2.0))

# 하이퍼파라미터 설정
iters = 10000   # 반복 횟수
lr = 0.001      # 학습률

# 경사 하강 반복
for i in range(iters):
    print(X0, X1)
    Y = rosenbrock(X0, X1)

    # 이전 반복에서 더해진 미분 초기화
    X0.cleargrad()
    X1.cleargrad()

    # 미분(역전파)
    Y.backward()

    # 변수 갱신
    X0.data -= lr * X0.grad.data
    X1.data -= lr * X1.grad.data

print(X0, X1)

```

- dezero.model과 dezero.layers 사용함

```python
import numpy as np
from dezero import Model
import dezero.layers as L
import dezero.functions as F

# -----------------------------
# 1. 데이터셋 생성
# -----------------------------
np.random.seed(0)
x = np.random.rand(100, 1)
y = np.sin(2 * np.pi * x) + np.random.rand(100, 1)

lr = 0.2        # 학습률
iters = 10000   # 반복 횟수

# -----------------------------
# 2. 2층 신경망 클래스 정의
# -----------------------------
class TwoLayerNet(Model):
    def __init__(self, hidden_size, out_size):
        super().__init__()
        self.l1 = L.Linear(hidden_size)
        self.l2 = L.Linear(out_size)

    def forward(self, x):
        y = F.sigmoid(self.l1(x))
        y = self.l2(y)
        return y

# -----------------------------
# 3. 모델 생성
# -----------------------------
model = TwoLayerNet(10, 1)

# -----------------------------
# 4. 학습 루프
# -----------------------------
for i in range(iters):
    y_pred = model.forward(x)   # 또는 model(x)
    loss = F.mean_squared_error(y, y_pred)

    # 기울기 초기화 및 역전파
    model.cleargrads()
    loss.backward()

    # 매개변수 갱신
    for p in model.params():
        p.data -= lr * p.grad.data

    # 1000회마다 손실 출력
    if i % 1000 == 0:
        print(loss.data)

```


### 옵티마이저(최적화 기법)

```python
import numpy as np
from dezero import Model
from dezero import optimizers   # 옵티마이저 패키지 임포트
import dezero.layers as L
import dezero.functions as F

# -----------------------------
# 1. 데이터셋 생성
# -----------------------------
np.random.seed(0)
x = np.random.rand(100, 1)
y = np.sin(2 * np.pi * x) + np.random.rand(100, 1)

lr = 0.2
iters = 10000

# -----------------------------
# 2. 2층 신경망 정의
# -----------------------------
class TwoLayerNet(Model):
    def __init__(self, hidden_size, out_size):
        super().__init__()
        self.l1 = L.Linear(hidden_size)
        self.l2 = L.Linear(out_size)

    def forward(self, x):
        y = F.sigmoid(self.l1(x))
        y = self.l2(y)
        return y

# -----------------------------
# 3. 모델 및 옵티마이저 생성
# -----------------------------
model = TwoLayerNet(10, 1)
optimizer = optimizers.SGD(lr)  # 확률적 경사하강법(SGD) 옵티마이저 생성
optimizer.setup(model)          # 모델 파라미터를 옵티마이저에 등록

# -----------------------------
# 4. 학습 루프
# -----------------------------
for i in range(iters):
    y_pred = model(x)
    loss = F.mean_squared_error(y, y_pred)

    model.cleargrads()
    loss.backward()

    optimizer.update()  # 옵티마이저로 매개변수 갱신

    if i % 1000 == 0:
        print(loss.data)

```

- 확률적 경사하강법(SGD): 데이터 중에서 무작위(확률적)으로 데이터를 선택하고, 선택된 데이터에 경사 하강법을 수행하는 최적화 기법을 구현한 옵티마이저
- 매개변수를 기울기 방향으로 lr배만큼 갱신함
- 기울기를 이용한 최적화 기법: Momentum, AdaGrad, AdaDelta, Adam


## Q러닝과 신경망

### 신경망의 전처리
- 신경망에서 '범주형 데이터'를 다룰 때 원-핫 벡터로 변환함
- 범주형 데이터는 전처리 과정에서 원-핫 벡터로 만듦
  - 예) 옷 사이즈(S/M/L), 혈액형(A/B/O/AB)
- 원-핫 벡터: 여러 원소 중 하나만 1이고 다른 원소는 모두 0인 벡터

#### 원-핫 벡터 관련 코드
- 신경망에서는 데이터를 모아서 배치로 처리함
- 예) 100개의 데이터를 한꺼번에 처리하면 형상이 (100, 12)인 데이터를 입력함

```python
import numpy as np

# -----------------------------
# 1. 원-핫 벡터 생성 함수
# -----------------------------
def one_hot(state):
    # 벡터 준비
    HEIGHT, WIDTH = 3, 4
    vec = np.zeros(HEIGHT * WIDTH, dtype=np.float32)

    # state에 해당하는 원소만 1.0으로 설정
    y, x = state
    idx = WIDTH * y + x
    vec[idx] = 1.0

    # 배치 처리를 위해 새 축 추가
    return vec[np.newaxis, :]

# -----------------------------
# 2. 테스트
# -----------------------------
state = (2, 0)
x = one_hot(state)

print(x.shape)  # (1, 12)
print(x)        # [[0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]]

```

### Q 함수를 표현하는 신경망

### 2 가지 신경망 구조
- Q는 (state, action) 쌍의 데이터를 입력받아 Q함수의 값을 출력함
- (state, action) 쌍의 데이터 하나하나에 대해 Q함수의 값이 개별적으로 저장됨

<img width="386" height="275" alt="image" src="https://github.com/user-attachments/assets/20888bbb-fdea-4456-8b02-4c8ca534068d" />

#### 첫 번째 구조: 상태와 행동 두 가지를 입력으로 받는 신경망
- 출력으로는 Q함수의 값을 하나만 내보냄
- 계산 비용 측면에서 문제가 있음
- Q 함수의 최댓값을 구하는 계산 비용이 커짐

#### 두 번째 구조: 상태만을 입력받아 가능한 행동의 개수만큼 Q함수의 값을 출력하는 신경망
- 행동의 가짓수가 4개라면 원소 4개짜리 벡터를 출력함

#### (상태만을 입력받는) 두 번째 구조 코드
- 2계층의 완전 연결 형태로 구성됨

```python
from dezero import Model
import dezero.functions as F
import dezero.layers as L

# -----------------------------
# 1. Q-네트워크 정의
# -----------------------------
class QNet(Model):
    def __init__(self):
        super().__init__()
        self.l1 = L.Linear(100)  # 중간층 크기
        self.l2 = L.Linear(4)    # 가능한 행동의 개수

    def forward(self, x):
        x = F.relu(self.l1(x))
        x = self.l2(x)
        return x

# -----------------------------
# 2. 모델 생성 및 테스트
# -----------------------------
qnet = QNet()

state = (2, 0)
state = one_hot(state)  # 원-핫 벡터로 변환

qs = qnet(state)
print(qs.shape)  # (1, 4)

```

### 신경망과 Q러닝

- Q러닝 간소화
<br>
<img width="273" height="39" alt="image" src="https://github.com/user-attachments/assets/fc9eadaf-acbc-4a3a-a887-05248aa356e9" />
<br>

- 입력 S_t, A_t일 때 출력이 T가 되도록 Q 함수를 갱신하는 것으로 해석함
- T: 정답 레이블 (스칼라 값이기 때문에 회귀문제로 생각할 수 있음)

#### Q러닝을 수행하는 에이전트

- 전반부 코드
```python
# -----------------------------
# Q-Learning 에이전트 (일부 코드)
# -----------------------------
class QLearningAgent:
    ...

    def update(self, state, action, reward, next_state, done):
        # 다음 상태에서 최대가 되는 Q 함수의 값을 계산 (next_q)
        if done:
            # 목표 상태에 도달한 경우 (Q 함수는 항상 0)
            next_q = np.zeros(1)
        else:
            # 그 외 상태
            next_qs = self.qnet(next_state)
            next_q = next_qs.max(axis=1)

```

- Q 함수 갱신

```python
class QLearningAgent:
    def __init__(self):
        self.gamma = 0.9      # 할인율
        self.lr = 0.01        # 학습률
        self.epsilon = 0.1    # 탐험 확률 (ε-greedy)
        self.action_size = 4  # 가능한 행동의 개수

        # Q-네트워크 및 옵티마이저 초기화
        self.qnet = QNet()
        self.optimizer = optimizers.SGD(self.lr)
        self.optimizer.setup(self.qnet)

    # -----------------------------
    # 행동 선택 (ε-greedy 정책)
    # -----------------------------
    def get_action(self, state):
        if np.random.rand() < self.epsilon:
            # 무작위 행동 선택 (탐험)
            return np.random.choice(self.action_size)
        else:
            # Q값이 가장 큰 행동 선택 (활용)
            qs = self.qnet(state)
            return qs.data.argmax()

    # -----------------------------
    # Q 함수 갱신
    # -----------------------------
    def update(self, state, action, reward, next_state, done):
        # 다음 상태에서 최대 Q값 계산
        with dezero.no_grad():
            next_qs = self.qnet(next_state)
            next_q = next_qs.max(axis=1)

        # 목표값 계산 (Bellman equation)
        target = self.gamma * next_q + reward
        if done:
            target = reward  # 에피소드 종료 시 다음 상태 없음

        # 현재 상태의 Q값 계산
        qs = self.qnet(state)
        q = qs[:, action]

        # 손실(MSE) 계산
        loss = F.mean_squared_error(target, q)

        # 역전파 및 파라미터 갱신
        self.qnet.cleargrads()
        loss.backward()
        self.optimizer.update()

        return loss.data

```

 ##### 에이전트 실행
 
```python
# -----------------------------
# Q-Learning 학습 루프
# -----------------------------
env = GridWorld()
agent = QLearningAgent()

episodes = 1000       # 에피소드 수
loss_history = []     # 손실값 저장용 리스트

for episode in range(episodes):
    state = env.reset()
    state = one_hot(state)
    total_loss, cnt = 0, 0
    done = False

    while not done:
        # 행동 선택
        action = agent.get_action(state)

        # 환경으로부터 다음 상태, 보상, 종료 여부 획득
        next_state, reward, done = env.step(action)
        next_state = one_hot(next_state)

        # Q 함수 업데이트
        loss = agent.update(state, action, reward, next_state, done)
        total_loss += loss
        cnt += 1

        # 상태 갱신
        state = next_state

    # 평균 손실 계산 및 저장
    average_loss = total_loss / cnt
    loss_history.append(average_loss)

```

 ##### 에피소드별 손실 추이
- 신경망을 이용한 강화학습에서는 손실이 안정되게 나오지 않는 경우가 많음
- 에피소드를 거듭할수록 손실이 작아지고 있음
<br>
  <img width="408" height="312" alt="image" src="https://github.com/user-attachments/assets/8f9cc962-7352-46c1-b763-4a749ac06f94" />
<br>

 ##### 신경망을 이용한 Q러닝으로 얻은 Q함수와 정책
- 에피소드 횟수를 늘리면 최적 정책에 가까운 정책을 안정적으로 얻을 수 있음
<br>
<img width="521" height="196" alt="image" src="https://github.com/user-attachments/assets/87a3f133-afd5-43b9-b0b5-05a4dfcad86a" />
<br>








  



 

  










